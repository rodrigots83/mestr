library(tidyverse)
library(tidytext)
library(textrank)
library(rvest)
## LENDO O DOCUMENTO QUE NECESSITA SER SUMARIZADO
dados = read.csv(file = "Trends_pesquisa.csv", header = FALSE, sep = ";", stringsAsFactors = FALSE, encoding = "UTF-8")
palavras <- as.vector(dados[1,])
final <- ""
resultado <- ""
for(i in 1:length(dados)){
final = tm::removePunctuation(x = final)
resultado <- paste(resultado, final)
}
print(resultado)
## INSTALANDO PACOTES NECESSÁRIOS
# install.packages("tidyverse")
# install.packages("tidytext")
# install.packages("textrank")
# install.packages("rvest")
## CARREGANDO OS PACOTES NECESSÁRIOS
library(tidyverse)
library(tidytext)
library(textrank)
library(rvest)
## LENDO O DOCUMENTO QUE NECESSITA SER SUMARIZADO
dados = read.csv(file = "Trends_pesquisa.csv", header = FALSE, sep = ";", stringsAsFactors = FALSE, encoding = "UTF-8")
palavras <- as.vector(dados[1,])
final <- ""
resultado <- ""
for(i in 1:length(dados)){
final = tm::removePunctuation(x = palavras[1,i])
resultado <- paste(resultado, final)
}
print(resultado)
## INSTALANDO PACOTES NECESSÁRIOS
# install.packages("tidyverse")
# install.packages("tidytext")
# install.packages("textrank")
# install.packages("rvest")
## CARREGANDO OS PACOTES NECESSÁRIOS
library(tidyverse)
library(tidytext)
library(textrank)
library(rvest)
## LENDO O DOCUMENTO QUE NECESSITA SER SUMARIZADO
dados = read.csv(file = "Trends_pesquisa.csv", header = FALSE, sep = ";", stringsAsFactors = FALSE, encoding = "UTF-8")
palavras <- as.vector(dados[1,])
final <- ""
resultado <- ""
for(i in 1:length(dados)){
final = tm::removePunctuation(x = tolower(palavras[1,i])
resultado <- paste(resultado, final)
}
print(resultado)
## INSTALANDO PACOTES NECESSÁRIOS
# install.packages("tidyverse")
# install.packages("tidytext")
# install.packages("textrank")
# install.packages("rvest")
## CARREGANDO OS PACOTES NECESSÁRIOS
library(tidyverse)
library(tidytext)
library(textrank)
library(rvest)
## LENDO O DOCUMENTO QUE NECESSITA SER SUMARIZADO
dados = read.csv(file = "Trends_pesquisa.csv", header = FALSE, sep = ";", stringsAsFactors = FALSE, encoding = "UTF-8")
palavras <- as.vector(dados[1,])
final <- ""
resultado <- ""
for(i in 1:length(dados)){
final = tm::removePunctuation(x = tolower(palavras[1,i]))
resultado <- paste(resultado, final)
}
print(resultado)
## INSTALANDO PACOTES NECESSÁRIOS
# install.packages("tidyverse")
# install.packages("tidytext")
# install.packages("textrank")
# install.packages("rvest")
## CARREGANDO OS PACOTES NECESSÁRIOS
library(tidyverse)
library(tidytext)
library(textrank)
library(rvest)
## LENDO O DOCUMENTO QUE NECESSITA SER SUMARIZADO
dados = read.csv(file = "Trends_pesquisa.csv", header = FALSE, sep = ";", stringsAsFactors = FALSE, encoding = "UTF-8")
palavras <- as.vector(dados[1,])
final <- ""
resultado <- ""
for(i in 1:length(dados)){
final = tm::removeWords(x = tolower(dados[1,i]),  words = stopwords::stopwords("en"))
final = tm::removeWords(x = tolower(dados[1,i]),  words = stopwords::stopwords("pt"))
final = tm::removeWords(x = tolower(dados[1,i]),  words = c('different', 'due', 'increase', 'issues', 'international', 'leading', 'major', 'model', 'movements', 'possibility', 'replacing', 'role', 'support', 'union', 'use', 'varios', 'various', 'continente', 'life', 'movements'))
final = tm::removePunctuation(x = final)
final = gsub(' ai ', 'artificial_intelligence', final)
final = gsub('artificial intelligence', 'artificial_intelligence', final)
final = gsub('south america', 'south_america', final)
final = gsub('south american', 'south_america', final)
final = gsub('latin america', 'latin_america', final)
final = gsub('latin american', 'latin_america', final)
final = gsub('climate change', 'climate_change', final)
final = gsub('financial crises', 'financial_crises', final)
final = gsub('middle east', 'middle_east', final)
final = gsub('energy matrix', 'matrix', final)
final = gsub('energy model', 'matrix', final)
final = gsub('tecnological', 'technologies', final)
final = gsub('technological', 'technologies', final)
final = gsub('wars', 'war', final)
final = gsub('growing', 'growth', final)
final = gsub('migratory', 'migration', final)
final = gsub('chineses', 'china', final)
final = gsub('chinese', 'china', final)
final = gsub('powers', 'power', final)
final = gsub('break', 'disruption', final)
resultado <- paste(resultado, final)
}
print(resultado)
tibble(text = resultado)
sentencas <- tibble(text = resultado)
sentencas
sentencas <- tibble(text = "meu texto é um texto que tem muito texto longo")
sentencas
sentencas <- tibble(text = dados)
sentencas
dados
sentencas <- tibble(text = dados)
sentencas
unnest_tokens(sentences, text, token = "sentences")
sentencas <- tibble(text = dados) %>% unnest_tokens(sentences, text, token = "sentences")
sentencas <- tibble(text = dados)
unnest_tokens(sentences, text, token = "sentencas")
sentencas <- tibble(text = dados)
unnest_tokens(sentencas, text, token = "sentencas")
unnest_tokens(sentences, text, token = "sentences")
sentencas
sentencas <- tibble(text = dados)
unnest_tokens(sentences, text, token = "sentences")
unnest_tokens(sentencas, token = "words", format = "text")
unnest_tokens(sentencas, token = "words", format = "text")
unnest_tokens(sentencas, input = sentencas, token = "words", format = "text")
unnest_tokens(sentencas, input = sentencas$text, token = "words", format = "text")
unnest_tokens(token = "words", format = "text")
sentencas <- tibble(text = dados) %>% unnest_tokens(token = "words", format = "text")
sentencas <- tibble(text = dados) %>% unnest_tokens(input = dados, token = "words", format = "text")
unnest_tokens(input = dados, token = "words", format = "text")
sentencas <- tibble(txt = dados)
sentencas <- unnest_tokens(word, txt)
sentencas
sentencas <- tibble(txt = dados)
sentencas <- unnest_tokens(sentence, txt, token = "sentences")
sentencas
sentencas <- tibble(txt = dados)
sentencas
sentencas <- tibble(text = dados)
sentencas
sentencas <- tibble(texto = dados)
sentencas
sentencas <- unnest_tokens(word, txt)
sentencas
unnest_tokens(word, txt)
sentencas %>% unnest_tokens(word, txt)
sentencas
sentencas <- tibble(txt = dados) %>% unnest_tokens(word, txt)
sentencas
sentencas <- tibble(txt = dados) %>% unnest_tokens(word, txt)
sentencas <- tibble(txt = dados)
sentencas <- tibble(txt = dados)
sentencas
## INSTALANDO PACOTES NECESSÁRIOS
# install.packages("tidyverse")
# install.packages("tidytext")
# install.packages("textrank")
# install.packages("rvest")
## CARREGANDO OS PACOTES NECESSÁRIOS
library(tidyverse)
library(tidytext)
library(textrank)
library(rvest)
## LENDO O DOCUMENTO QUE NECESSITA SER SUMARIZADO
dados = read.csv(file = "Trends_pesquisa.csv", header = FALSE, sep = ";", stringsAsFactors = FALSE, encoding = "UTF-8")
palavras <- as.vector(dados[1,])
final <- ""
resultado <- ""
for(i in 1:length(dados)){
# final = tm::removeWords(x = tolower(dados[1,i]),  words = stopwords::stopwords("en"))
# final = tm::removeWords(x = tolower(dados[1,i]),  words = stopwords::stopwords("pt"))
#
# final = tm::removeWords(x = tolower(dados[1,i]),  words = c('different', 'due', 'increase', 'issues', 'international', 'leading', 'major', 'model', 'movements', 'possibility', 'replacing', 'role', 'support', 'union', 'use', 'varios', 'various', 'continente', 'life', 'movements'))
# final = tm::removePunctuation(x = final)
#
# final = gsub(' ai ', 'artificial_intelligence', final)
# final = gsub('artificial intelligence', 'artificial_intelligence', final)
# final = gsub('south america', 'south_america', final)
# final = gsub('south american', 'south_america', final)
# final = gsub('latin america', 'latin_america', final)
# final = gsub('latin american', 'latin_america', final)
# final = gsub('climate change', 'climate_change', final)
# final = gsub('financial crises', 'financial_crises', final)
# final = gsub('middle east', 'middle_east', final)
# final = gsub('energy matrix', 'matrix', final)
# final = gsub('energy model', 'matrix', final)
#
# final = gsub('tecnological', 'technologies', final)
# final = gsub('technological', 'technologies', final)
# final = gsub('wars', 'war', final)
# final = gsub('growing', 'growth', final)
# final = gsub('migratory', 'migration', final)
# final = gsub('chineses', 'china', final)
# final = gsub('chinese', 'china', final)
# final = gsub('powers', 'power', final)
# final = gsub('break', 'disruption', final)
resultado <- paste(resultado, final)
}
print(resultado)
## INSTALANDO PACOTES NECESSÁRIOS
# install.packages("tidyverse")
# install.packages("tidytext")
# install.packages("textrank")
# install.packages("rvest")
## CARREGANDO OS PACOTES NECESSÁRIOS
library(tidyverse)
library(tidytext)
library(textrank)
library(rvest)
## LENDO O DOCUMENTO QUE NECESSITA SER SUMARIZADO
dados = read.csv(file = "Trends_pesquisa.csv", header = FALSE, sep = ";", stringsAsFactors = FALSE, encoding = "UTF-8")
palavras <- as.vector(dados[1,])
final <- ""
resultado <- ""
for(i in 1:length(dados)){
# final = tm::removeWords(x = tolower(dados[1,i]),  words = stopwords::stopwords("en"))
# final = tm::removeWords(x = tolower(dados[1,i]),  words = stopwords::stopwords("pt"))
#
# final = tm::removeWords(x = tolower(dados[1,i]),  words = c('different', 'due', 'increase', 'issues', 'international', 'leading', 'major', 'model', 'movements', 'possibility', 'replacing', 'role', 'support', 'union', 'use', 'varios', 'various', 'continente', 'life', 'movements'))
# final = tm::removePunctuation(x = final)
#
# final = gsub(' ai ', 'artificial_intelligence', final)
# final = gsub('artificial intelligence', 'artificial_intelligence', final)
# final = gsub('south america', 'south_america', final)
# final = gsub('south american', 'south_america', final)
# final = gsub('latin america', 'latin_america', final)
# final = gsub('latin american', 'latin_america', final)
# final = gsub('climate change', 'climate_change', final)
# final = gsub('financial crises', 'financial_crises', final)
# final = gsub('middle east', 'middle_east', final)
# final = gsub('energy matrix', 'matrix', final)
# final = gsub('energy model', 'matrix', final)
#
# final = gsub('tecnological', 'technologies', final)
# final = gsub('technological', 'technologies', final)
# final = gsub('wars', 'war', final)
# final = gsub('growing', 'growth', final)
# final = gsub('migratory', 'migration', final)
# final = gsub('chineses', 'china', final)
# final = gsub('chinese', 'china', final)
# final = gsub('powers', 'power', final)
# final = gsub('break', 'disruption', final)
# resultado <- paste(resultado, final)
resultado <- paste(resultado, dados[1,i])
}
print(resultado)
sentencas <- tibble(txt = dados)
sentencas
sentencas <- tibble(txt = dados) %>% unnest_tokens(word, txt)
sentencas <- tibble(txt = dados)
sentencas
sentencas <- tibble(txt = dados)
sentencas
sentencas %>% unnest_tokens(word, txt)
length(sentencas)
length(resultado
length(resultado)
length(resultado)
length(dados)
sentencas <- tibble(line = 1:length(dados), txt = dados)
sentencas
sentencas %>% unnest_tokens(word, txt)
sentencas <- tibble(line = 1:length(palavras), txt = palavras)
sentencas
sentencas <- tibble(line = 1:length(palavras), txt = palavras[1:4])
sentencas
sentencas <- tibble(line = 1:length(palavras[1,4]), txt = palavras[1:4])
sentencas
sentencas %>% unnest_tokens(word, txt)
sentencas
sentencas <- tibble(line = 1:length(palavras[1,4]), text = palavras[1:4])
sentencas
View(sentencas)
sentencas <- tibble(line = 1:length(palavras[1,4]), text = text)
View(sentencas)
text <- palavras[1,4]
sentencas <- tibble(line = 1:length(palavras[1,4]), text = text)
sentencas
text <- palavras[1,4]
sentencas <- tibble(line = 1:4, text = text)
sentencas
text <- palavras[1,4]
text
palavras[1,4]
palavras[1,4]
palavras[1:4]
text <- palavras[1:4]
text
sentencas <- tibble(line = 1:4, text = text)
sentencas
text <- c("Urban traffic crisis.",
"China's rise as a great power has the potential to rewire global economic, diplomatic, and civil society relationships.",
"Emerging technologies (such as AI and automation) will threaten traditional developmental pathways for less developed countries.",
"Increased citizen participation in community and global issues.")
text
palavras[1:4]
as.list(palavras[1:4])
as.vector(palavras[1:4])
as.array(palavras[1:4])
as.factor(palavras[1:4])
sentencas <- tibble(line = 1:4, text = text)
sentencas
sentencas %>% unnest_tokens(word, txt)
sentencas
as.vector(palavras[1:4], mode = "text")
as.vector(palavras[1:4], mode = "list")
palavras[1:4]
palavras <- as.vector(dados[1,], mode = "list")
palavras
palavras <- as.list(dados[1,], mode = "list")
palavras
sentencas <- tibble(line = 1:4, text = palvras)
sentencas
length(palavras)
sentencas <- tibble(line = 1:length(palavras), text = palavras)
sentencas
View(sentencas)
sentencas %>% unnest_tokens(word, txt)
sentencas
sentencas %>% unnest_tokens(word, text)
sentencas
sentencas <- unnest_tokens(word, text)
sentencas
sentencas <- tibble(line = 1:length(palavras), text = palavras)
# View(sentencas)
sentencas %>% unnest_tokens(word, text)
sentencas <- tibble(line = 1:length(palavras), text = palavras) %>% unnest_tokens(word, text)
sentencas
View(sentencas)
palavras <- as.list(dados[1,], mode = "list")
palavras <- tm::removeWords(x = tolower(palavras),  words = stopwords::stopwords("en"))
palavras
## INSTALANDO PACOTES NECESSÁRIOS
# install.packages("tidyverse")
# install.packages("tidytext")
# install.packages("textrank")
# install.packages("rvest")
## CARREGANDO OS PACOTES NECESSÁRIOS
library(tidyverse)
library(tidytext)
library(textrank)
library(rvest)
## LENDO O DOCUMENTO QUE NECESSITA SER SUMARIZADO
dados = read.csv(file = "Trends_pesquisa.csv", header = FALSE, sep = ";", stringsAsFactors = FALSE, encoding = "UTF-8")
palavras <- as.list(dados[1,], mode = "list")
palavras <- tm::removeWords(x = tolower(palavras),  words = stopwords::stopwords("en"))
palavras
final <- ""
resultado <- ""
for(i in 1:length(dados)){
# final = tm::removeWords(x = tolower(dados[1,i]),  words = stopwords::stopwords("en"))
# final = tm::removeWords(x = tolower(dados[1,i]),  words = stopwords::stopwords("pt"))
#
# final = tm::removeWords(x = tolower(dados[1,i]),  words = c('different', 'due', 'increase', 'issues', 'international', 'leading', 'major', 'model', 'movements', 'possibility', 'replacing', 'role', 'support', 'union', 'use', 'varios', 'various', 'continente', 'life', 'movements'))
# final = tm::removePunctuation(x = final)
#
# final = gsub(' ai ', 'artificial_intelligence', final)
# final = gsub('artificial intelligence', 'artificial_intelligence', final)
# final = gsub('south america', 'south_america', final)
# final = gsub('south american', 'south_america', final)
# final = gsub('latin america', 'latin_america', final)
# final = gsub('latin american', 'latin_america', final)
# final = gsub('climate change', 'climate_change', final)
# final = gsub('financial crises', 'financial_crises', final)
# final = gsub('middle east', 'middle_east', final)
# final = gsub('energy matrix', 'matrix', final)
# final = gsub('energy model', 'matrix', final)
#
# final = gsub('tecnological', 'technologies', final)
# final = gsub('technological', 'technologies', final)
# final = gsub('wars', 'war', final)
# final = gsub('growing', 'growth', final)
# final = gsub('migratory', 'migration', final)
# final = gsub('chineses', 'china', final)
# final = gsub('chinese', 'china', final)
# final = gsub('powers', 'power', final)
# final = gsub('break', 'disruption', final)
# resultado <- paste(resultado, final)
}
# print(resultado)
# palavras[1:4]
#
# as.vector(palavras[1:4], mode = "list")
#
# palavras[1:4]
#
# text <- c("Urban traffic crisis.",
#           "China's rise as a great power has the potential to rewire global economic, diplomatic, and civil society relationships.",
#           "Emerging technologies (such as AI and automation) will threaten traditional developmental pathways for less developed countries.",
#           "Increased citizen participation in community and global issues.")
#
# text
length(palavras)
sentencas <- tibble(line = 1:length(palavras), text = palavras) %>% unnest_tokens(word, text)
View(sentencas)
## INSTALANDO PACOTES NECESSÁRIOS
# install.packages("tidyverse")
# install.packages("tidytext")
# install.packages("textrank")
# install.packages("rvest")
## CARREGANDO OS PACOTES NECESSÁRIOS
library(tidyverse)
library(tidytext)
library(textrank)
library(rvest)
## LENDO O DOCUMENTO QUE NECESSITA SER SUMARIZADO
dados = read.csv(file = "Trends_pesquisa.csv", header = FALSE, sep = ";", stringsAsFactors = FALSE, encoding = "UTF-8")
palavras <- as.list(dados[1,], mode = "list")
palavras <- tm::removeWords(x = tolower(palavras),  words = stopwords::stopwords("en"))
palavras
final <- ""
resultado <- ""
# for(i in 1:length(dados)){
#   # final = tm::removeWords(x = tolower(dados[1,i]),  words = stopwords::stopwords("en"))
#   # final = tm::removeWords(x = tolower(dados[1,i]),  words = stopwords::stopwords("pt"))
#   #
#   # final = tm::removeWords(x = tolower(dados[1,i]),  words = c('different', 'due', 'increase', 'issues', 'international', 'leading', 'major', 'model', 'movements', 'possibility', 'replacing', 'role', 'support', 'union', 'use', 'varios', 'various', 'continente', 'life', 'movements'))
#   # final = tm::removePunctuation(x = final)
#   #
#   # final = gsub(' ai ', 'artificial_intelligence', final)
#   # final = gsub('artificial intelligence', 'artificial_intelligence', final)
#   # final = gsub('south america', 'south_america', final)
#   # final = gsub('south american', 'south_america', final)
#   # final = gsub('latin america', 'latin_america', final)
#   # final = gsub('latin american', 'latin_america', final)
#   # final = gsub('climate change', 'climate_change', final)
#   # final = gsub('financial crises', 'financial_crises', final)
#   # final = gsub('middle east', 'middle_east', final)
#   # final = gsub('energy matrix', 'matrix', final)
#   # final = gsub('energy model', 'matrix', final)
#   #
#   # final = gsub('tecnological', 'technologies', final)
#   # final = gsub('technological', 'technologies', final)
#   # final = gsub('wars', 'war', final)
#   # final = gsub('growing', 'growth', final)
#   # final = gsub('migratory', 'migration', final)
#   # final = gsub('chineses', 'china', final)
#   # final = gsub('chinese', 'china', final)
#   # final = gsub('powers', 'power', final)
#   # final = gsub('break', 'disruption', final)
#   # resultado <- paste(resultado, final)
# }
# print(resultado)
sentencas <- tibble(line = 1:length(palavras), text = palavras) %>% unnest_tokens(word, text)
View(sentencas)
## INSTALANDO PACOTES NECESSÁRIOS
# install.packages("tidyverse")
# install.packages("tidytext")
# install.packages("textrank")
# install.packages("rvest")
## CARREGANDO OS PACOTES NECESSÁRIOS
library(tidyverse)
library(tidytext)
library(textrank)
library(rvest)
## LENDO O DOCUMENTO QUE NECESSITA SER SUMARIZADO
dados = read.csv(file = "Trends_pesquisa.csv", header = FALSE, sep = ";", stringsAsFactors = FALSE, encoding = "UTF-8")
palavras <- as.list(dados[1,], mode = "list")
palavras <- tm::removeWords(x = tolower(palavras),  words = stopwords::stopwords("en"))
palavras
final <- ""
resultado <- ""
# for(i in 1:length(dados)){
#   # final = tm::removeWords(x = tolower(dados[1,i]),  words = stopwords::stopwords("en"))
#   # final = tm::removeWords(x = tolower(dados[1,i]),  words = stopwords::stopwords("pt"))
#   #
#   # final = tm::removeWords(x = tolower(dados[1,i]),  words = c('different', 'due', 'increase', 'issues', 'international', 'leading', 'major', 'model', 'movements', 'possibility', 'replacing', 'role', 'support', 'union', 'use', 'varios', 'various', 'continente', 'life', 'movements'))
#   # final = tm::removePunctuation(x = final)
#   #
#   # final = gsub(' ai ', 'artificial_intelligence', final)
#   # final = gsub('artificial intelligence', 'artificial_intelligence', final)
#   # final = gsub('south america', 'south_america', final)
#   # final = gsub('south american', 'south_america', final)
#   # final = gsub('latin america', 'latin_america', final)
#   # final = gsub('latin american', 'latin_america', final)
#   # final = gsub('climate change', 'climate_change', final)
#   # final = gsub('financial crises', 'financial_crises', final)
#   # final = gsub('middle east', 'middle_east', final)
#   # final = gsub('energy matrix', 'matrix', final)
#   # final = gsub('energy model', 'matrix', final)
#   #
#   # final = gsub('tecnological', 'technologies', final)
#   # final = gsub('technological', 'technologies', final)
#   # final = gsub('wars', 'war', final)
#   # final = gsub('growing', 'growth', final)
#   # final = gsub('migratory', 'migration', final)
#   # final = gsub('chineses', 'china', final)
#   # final = gsub('chinese', 'china', final)
#   # final = gsub('powers', 'power', final)
#   # final = gsub('break', 'disruption', final)
#   # resultado <- paste(resultado, final)
# }
# print(resultado)
sentencas <- tibble(line = 1:length(palavras), text = palavras) %>% unnest_tokens(word, text)
View(sentencas)
sentencas %>% count(word, sort = TRUE)
ggplot(data = sentencas, aes(word, n))
